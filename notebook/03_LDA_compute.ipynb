{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peripheral-netherlands",
   "metadata": {},
   "source": [
    "# Etude des sujets des amendements PLFSS (LDA)\n",
    "\n",
    "## Calcul des thématiques\n",
    "\n",
    "Basé sur https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q --upgrade pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "amdt = pd.read_csv('./data/amdt_sans_stopword.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-college",
   "metadata": {},
   "source": [
    "# Analyse des thématiques par LDA\n",
    "\n",
    "LDA : https://fr.wikipedia.org/wiki/Allocation_de_Dirichlet_latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "NUM_TOPICS = 15\n",
    " \n",
    "# vectorizer = CountVectorizer(min_df=5, max_df=0.9, \n",
    "#                              stop_words='french', lowercase=True, \n",
    "#                              token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "vectorizer = CountVectorizer()\n",
    "data_vectorized = vectorizer.fit_transform(amdt[\"txt_sans_stopword\"])\n",
    " \n",
    "# Build a Latent Dirichlet Allocation Model\n",
    "# n_jobs = -1 to use all CPU core\n",
    "lda_model = LatentDirichletAllocation(n_components=NUM_TOPICS, max_iter=10, learning_method='online', n_jobs = -1)\n",
    "lda_Z = lda_model.fit_transform(data_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-jesus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_decay': [0.5], 'learning_method': ['online'],\n",
       "                         'max_iter': [10], 'n_components': [3],\n",
       "                         'n_jobs': [-1]})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define Search Param\n",
    "search_params = {'n_components': [i for i in range(3,4)],\n",
    "                'learning_decay': [.5], # [.5, .7, .9]\n",
    "                'max_iter' : [10],\n",
    "                'learning_method':['online'],\n",
    "                'n_jobs':[-1]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-virus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'learning_method': 'online', 'max_iter': 10, 'n_components': 3, 'n_jobs': -1}\n",
      "Best Log Likelihood Score:  -919354.8796033779\n",
      "Model Perplexity:  2252.043944176753\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([16.50784359]),\n",
       " 'std_fit_time': array([0.73690747]),\n",
       " 'mean_score_time': array([0.13072748]),\n",
       " 'std_score_time': array([0.01201381]),\n",
       " 'param_learning_decay': masked_array(data=[0.5],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_method': masked_array(data=['online'],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[10],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_components': masked_array(data=[3],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_jobs': masked_array(data=[-1],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_decay': 0.5,\n",
       "   'learning_method': 'online',\n",
       "   'max_iter': 10,\n",
       "   'n_components': 3,\n",
       "   'n_jobs': -1}],\n",
       " 'split0_test_score': array([-994870.41586479]),\n",
       " 'split1_test_score': array([-839108.80416651]),\n",
       " 'split2_test_score': array([-908731.90673079]),\n",
       " 'split3_test_score': array([-1037968.87546368]),\n",
       " 'split4_test_score': array([-816094.39579112]),\n",
       " 'mean_test_score': array([-919354.87960338]),\n",
       " 'std_test_score': array([86008.00418985]),\n",
       " 'rank_test_score': array([1], dtype=int32)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-patrick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-coupon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscore['params'][0]['learning_decay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Log Likelyhoods from Grid Search Output\n",
    "# n_topics = [10, 15, 20, 25, 30]\n",
    "# log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.5]\n",
    "# log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.7]\n",
    "# log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.9]\n",
    "\n",
    "# # Show graph\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
    "# plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
    "# plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
    "# plt.title(\"Choosing Optimal LDA Model\")\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Log Likelyhood Scores\")\n",
    "# plt.legend(title='Learning decay', loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-programmer",
   "metadata": {},
   "source": [
    "# How to see the dominant topic in each document?\n",
    "\n",
    "To classify a document as belonging to a particular topic, a logical approach is to see which topic has the highest contribution to that document and assign it.\n",
    "\n",
    "In the table below, I’ve greened out all major topics in a document and assigned the most dominant topic in its own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_decay=0.5, learning_method='online',\n",
       "                          n_components=3, n_jobs=-1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_bc260_row0_col0,#T_bc260_row1_col1,#T_bc260_row1_col3,#T_bc260_row2_col1,#T_bc260_row2_col3,#T_bc260_row3_col1,#T_bc260_row3_col2,#T_bc260_row3_col3,#T_bc260_row4_col0,#T_bc260_row4_col1,#T_bc260_row4_col2,#T_bc260_row4_col3,#T_bc260_row5_col0,#T_bc260_row5_col1,#T_bc260_row5_col3,#T_bc260_row6_col1,#T_bc260_row6_col2,#T_bc260_row6_col3,#T_bc260_row7_col1,#T_bc260_row7_col2,#T_bc260_row7_col3,#T_bc260_row8_col0,#T_bc260_row8_col1,#T_bc260_row8_col3,#T_bc260_row9_col1,#T_bc260_row9_col2,#T_bc260_row9_col3,#T_bc260_row10_col1,#T_bc260_row10_col2,#T_bc260_row10_col3,#T_bc260_row11_col0,#T_bc260_row11_col1,#T_bc260_row11_col3,#T_bc260_row12_col1,#T_bc260_row12_col3,#T_bc260_row13_col1,#T_bc260_row13_col3,#T_bc260_row14_col0,#T_bc260_row14_col1,#T_bc260_row14_col3{\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }#T_bc260_row0_col1,#T_bc260_row0_col2,#T_bc260_row0_col3,#T_bc260_row1_col0,#T_bc260_row1_col2,#T_bc260_row2_col0,#T_bc260_row2_col2,#T_bc260_row3_col0,#T_bc260_row5_col2,#T_bc260_row6_col0,#T_bc260_row7_col0,#T_bc260_row8_col2,#T_bc260_row9_col0,#T_bc260_row10_col0,#T_bc260_row11_col2,#T_bc260_row12_col0,#T_bc260_row12_col2,#T_bc260_row13_col0,#T_bc260_row13_col2,#T_bc260_row14_col2{\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }</style><table id=\"T_bc260_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Topic0</th>        <th class=\"col_heading level0 col1\" >Topic1</th>        <th class=\"col_heading level0 col2\" >Topic2</th>        <th class=\"col_heading level0 col3\" >dominant_topic</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bc260_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "                        <td id=\"T_bc260_row0_col0\" class=\"data row0 col0\" >0.990000</td>\n",
       "                        <td id=\"T_bc260_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "                        <td id=\"T_bc260_row1_col0\" class=\"data row1 col0\" >0.070000</td>\n",
       "                        <td id=\"T_bc260_row1_col1\" class=\"data row1 col1\" >0.930000</td>\n",
       "                        <td id=\"T_bc260_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "                        <td id=\"T_bc260_row2_col0\" class=\"data row2 col0\" >0.030000</td>\n",
       "                        <td id=\"T_bc260_row2_col1\" class=\"data row2 col1\" >0.960000</td>\n",
       "                        <td id=\"T_bc260_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "                        <td id=\"T_bc260_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row3_col1\" class=\"data row3 col1\" >0.730000</td>\n",
       "                        <td id=\"T_bc260_row3_col2\" class=\"data row3 col2\" >0.260000</td>\n",
       "                        <td id=\"T_bc260_row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "                        <td id=\"T_bc260_row4_col0\" class=\"data row4 col0\" >0.210000</td>\n",
       "                        <td id=\"T_bc260_row4_col1\" class=\"data row4 col1\" >0.570000</td>\n",
       "                        <td id=\"T_bc260_row4_col2\" class=\"data row4 col2\" >0.220000</td>\n",
       "                        <td id=\"T_bc260_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "                        <td id=\"T_bc260_row5_col0\" class=\"data row5 col0\" >0.470000</td>\n",
       "                        <td id=\"T_bc260_row5_col1\" class=\"data row5 col1\" >0.530000</td>\n",
       "                        <td id=\"T_bc260_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row5_col3\" class=\"data row5 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "                        <td id=\"T_bc260_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row6_col1\" class=\"data row6 col1\" >0.890000</td>\n",
       "                        <td id=\"T_bc260_row6_col2\" class=\"data row6 col2\" >0.110000</td>\n",
       "                        <td id=\"T_bc260_row6_col3\" class=\"data row6 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "                        <td id=\"T_bc260_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row7_col1\" class=\"data row7 col1\" >0.890000</td>\n",
       "                        <td id=\"T_bc260_row7_col2\" class=\"data row7 col2\" >0.110000</td>\n",
       "                        <td id=\"T_bc260_row7_col3\" class=\"data row7 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "                        <td id=\"T_bc260_row8_col0\" class=\"data row8 col0\" >0.420000</td>\n",
       "                        <td id=\"T_bc260_row8_col1\" class=\"data row8 col1\" >0.580000</td>\n",
       "                        <td id=\"T_bc260_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row8_col3\" class=\"data row8 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "                        <td id=\"T_bc260_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row9_col1\" class=\"data row9 col1\" >0.590000</td>\n",
       "                        <td id=\"T_bc260_row9_col2\" class=\"data row9 col2\" >0.410000</td>\n",
       "                        <td id=\"T_bc260_row9_col3\" class=\"data row9 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "                        <td id=\"T_bc260_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "                        <td id=\"T_bc260_row10_col1\" class=\"data row10 col1\" >0.780000</td>\n",
       "                        <td id=\"T_bc260_row10_col2\" class=\"data row10 col2\" >0.210000</td>\n",
       "                        <td id=\"T_bc260_row10_col3\" class=\"data row10 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "                        <td id=\"T_bc260_row11_col0\" class=\"data row11 col0\" >0.120000</td>\n",
       "                        <td id=\"T_bc260_row11_col1\" class=\"data row11 col1\" >0.870000</td>\n",
       "                        <td id=\"T_bc260_row11_col2\" class=\"data row11 col2\" >0.010000</td>\n",
       "                        <td id=\"T_bc260_row11_col3\" class=\"data row11 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "                        <td id=\"T_bc260_row12_col0\" class=\"data row12 col0\" >0.010000</td>\n",
       "                        <td id=\"T_bc260_row12_col1\" class=\"data row12 col1\" >0.990000</td>\n",
       "                        <td id=\"T_bc260_row12_col2\" class=\"data row12 col2\" >0.010000</td>\n",
       "                        <td id=\"T_bc260_row12_col3\" class=\"data row12 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "                        <td id=\"T_bc260_row13_col0\" class=\"data row13 col0\" >0.020000</td>\n",
       "                        <td id=\"T_bc260_row13_col1\" class=\"data row13 col1\" >0.940000</td>\n",
       "                        <td id=\"T_bc260_row13_col2\" class=\"data row13 col2\" >0.040000</td>\n",
       "                        <td id=\"T_bc260_row13_col3\" class=\"data row13 col3\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc260_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "                        <td id=\"T_bc260_row14_col0\" class=\"data row14 col0\" >0.150000</td>\n",
       "                        <td id=\"T_bc260_row14_col1\" class=\"data row14 col1\" >0.840000</td>\n",
       "                        <td id=\"T_bc260_row14_col2\" class=\"data row14 col2\" >0.010000</td>\n",
       "                        <td id=\"T_bc260_row14_col3\" class=\"data row14 col3\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa3eec24be0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "data = amdt[\"txt_sans_stopword\"]\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-valuation",
   "metadata": {},
   "source": [
    "# Review topics distribution across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-economics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Num</th>\n",
       "      <th>Num Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Num  Num Documents\n",
       "0          1           2923\n",
       "1          0           1460\n",
       "2          2            414"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-playlist",
   "metadata": {},
   "source": [
    "### Affecter un sujet à un texte en utilisant le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00155039 0.00155039 0.00155039 0.02860847 0.00155039 0.00155039\n",
      " 0.03950717 0.00155039 0.22440802 0.00155039 0.00155039 0.00155039\n",
      " 0.00155039 0.00155039 0.69042206] 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "text = \"Pour les entreprises de moins de 11 salariés, l’employeur est autorisé à attribuer une fois par an, à l’ensemble des salariés qu’il emploie, la prime exceptionnelle de pouvoir d’achat, dans les conditions prévues au V. »II. – En conséquence, compléter cet article par les deux alinéas suivants\"\n",
    "x = lda_model.transform(vectorizer.transform([text]))[0]\n",
    "print(x, x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4797, 15)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.97513153e-04, 4.97512448e-04, 4.97513049e-04, 4.97512770e-04,\n",
       "        4.97512929e-04, 4.97513086e-04, 4.97512786e-04, 4.97513071e-04,\n",
       "        4.97513451e-04, 4.97513135e-04, 4.97512821e-04, 4.97512990e-04,\n",
       "        4.97513258e-04, 4.97513055e-04, 9.93034818e-01]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda_Z contient les probabilités d'appartenance à un des S sujets pour chaque document\n",
    "lda_Z[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( vectorizer, open( \"./data/amdt_vectorizer.pickle\", \"wb\" ) )\n",
    "pickle.dump( data_vectorized, open( \"./data/amdt_data_vectorized.pickle\", \"wb\" ) )\n",
    "pickle.dump( lda_model, open( \"./data/amdt_lda_model.pickle\", \"wb\" ) )\n",
    "pickle.dump( lda_Z, open( \"./data/amdt_lda_Z.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-patient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-pierce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leximpact",
   "language": "python",
   "name": "leximpact"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
